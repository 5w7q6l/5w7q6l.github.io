# 利用Python实现酒店评论的情感分析


##  我的期末作业


> **采用机器学习方法实现对酒店评论数据的情感分类，利用Python语言实现情感分类模型的构建和预测，不包含理论部分**
## 1 开发环境准备
+ 1）**Jieba**
目前使用最为广泛的中文分词组件。下载地址：https://pypi.python.org/pypi/jieba/
+ 2）**Gensim**
用于主题模型、文档索引和大型语料相似度索引的python库，主要用于自然语言处理（NLP）和信息检索（IR）。下载地址：https://pypi.python.org/pypi/gensim
本实例中的维基中文语料处理和中文词向量模型构建需要用到该模块。
+ 3）**Pandas**
用于高效处理大型数据集、执行数据分析任务的python库，是基于Numpy的工具包。下载地址：https://pypi.python.org/pypi/pandas/0.20.1
+ 4）**Numpy**
用于存储和处理大型矩阵的工具包。下载地址：https://pypi.python.org/pypi/numpy
+ 5）**Scikit-learn**
用于机器学习的python工具包，python模块引用名字为sklearn，安装前还需要Numpy和Scipy两个Python库。官网地址：http://scikit-learn.org/stable/
+ 6）**Matplotlib**
Matplotlib是一个python的图形框架，用于绘制二维图形。下载地址：https://pypi.python.org/pypi/matplotlib
+ 7）**Tensorflow**
Tensorflow是一个采用数据流图用于数值计算的开源软件库，用于人工智能领域。
官网地址：http://www.tensorfly.cn/
下载地址：https://pypi.python.org/pypi/tensorflow/1.1.0
+ 8）**PyTorch**
PyTorch提供了丰富的工具和接口，可以帮助研究人员和开发人员更快地构建和训练深度学习模型。

## 2 数据获取
#### 2.1 停用词词典
本文使用中科院计算所中文自然语言处理开放平台发布的中文停用词表，包含了1208个停用词。下载地址：http://www.hicode.cc/download/view-software-13784.html
#### 2.2 正负向语料库
文本从http://www.datatang.com/data/11936 下载“有关中文情感挖掘的酒店评论语料”作为训练集与测试集，该语料包含了4种语料子集，本文选用正负各1000的平衡语料（ChnSentiCorp_htl_ba_2000）作为数据集进行分析。

## 3 数据预处理
#### 3.1 正负向语料预处理
为了方便之后的操作，需要把正向和负向评论分别规整到对应的一个txt文件中，即正向语料的集合文档（命名为2000_pos.txt）和负向语料的集合文档（命名为2000_neg.txt）。
运行完成后得到2000_pos.txt和2000_neg.txt两个文本文件，分别存放正向评论和负向评论

#### 3.2 中文文本分词
本文采用**结巴分词**分别对正向语料和负向语料进行分词处理。特别注意，在执行代码前需要把txt源文件手动转化成UTF-8格式，否则会报中文编码的错误。在进行分词前，需要对文本进行去除数字、字母和特殊符号的处理，使用python自带的**string**和**re**模块可以实现，其中string模块用于处理字符串操作，re模块用于正则表达式处理。
处理完成后，得到2000_pos_cut.txt和2000_neg_cut.txt两个txt文件，分别存放正负向语料分词后的结果。

#### 3.3 去停用词
分词完成后，即可读取停用词表中的停用词，对分词后的正负向语料进行匹配并去除停用词。去除停用词的步骤非常简单，主要有两个：

+ 1）读取停用词表；
+ 2）遍历分词后的句子，将每个词丢到此表中进行匹配，若停用词表存在则替换为空。

## 4 glove模型的实现
1. 整体思路
2. 数据准备
3. 构造共现矩阵
4. 得到序列
5. 创建数据管道
6. 模型构建
7. 模型训练
8. 加载模型测试

## 4.1 获取特征词向量
根据以上步骤得到了正负向语料的特征词文本，而模型的输入必须是数值型数据，因此需要将每条由词语组合而成的语句转化为一个数值型向量.
本文采用**Glove**词向量模型将语料转换为词向量。
获取特征词向量的主要步骤如下：

+ 1）读取模型词向量矩阵；
+ 2）遍历语句中的每个词，从模型词向量矩阵中抽取当前词的数值向量，一条语句即可得到一个二维矩阵，行数为词的个数，列数为模型设定的维度；
+ 3）根据得到的矩阵计算**矩阵均值**作为当前语句的特征词向量；
+ 4）全部语句计算完成后，拼接语句类别代表的值，写入csv文件中。

代码执行完成后，得到一个名为2000_data.csv的文件，第一列为类别对应的数值（1-pos, 0-neg），第二列开始为数值向量，每一行代表一条评论。

## 5 分类模型构建
本文采用支持向量机（SVM）作为本次实验的中文文本分类模型，其他分类模型采用相同的分析流程，在此不赘述。

支持向量机（SVM）是一种有监督的机器学习模型。本文首先采用经典的机器学习算法SVM作为分类器算法，通过计算测试集的预测精度和ROC曲线来验证分类器的有效性，一般来说ROC曲线的面积（AUC）越大模型的表现越好。
	
首先使用SVM作为分类器算法，随后利用matplotlib和metric库来构建ROC曲线。

## 6 逻辑回归
逻辑回归是一种用于分类问题的机器学习算法，它的主要思想是基于给定的输入特征，通过学习得到一个线性函数，将输入特征映射到一个实数范围内，然后通过一个逻辑函数（如sigmoid函数）将实数范围内的值转换为概率值，从而进行分类

使用逻辑回归对数据进行分类，并通过网格搜索来选择最优的超参数C和penalty。然后使用最优的超参数来训练模型，并对测试集进行预测，计算准确率、分类报告和AUC值，并绘制ROC曲线。
其中，train_test_split函数用于将数据集拆分为训练集和测试集。GridSearchCV函数用于进行网格搜索，寻找最优的超参数。LogisticRegression函数用于构建逻辑回归模型。accuracy_score函数用于计算准确率。classification_report函数用于生成分类报告。roc_auc_score函数用于计算AUC值。show_roc函数用于绘制ROC曲线。
需要注意的是，这段代码中的x_pca和y分别表示输入特征和标签，需要根据具体数据集进行修改

##  7 Xgboost 
Xgboost是一种基于决策树的集成学习算法，是Gradient Boosting算法的一种优化实现。它的主要思想是通过迭代地训练多个弱分类器（决策树），并将它们组合起来形成一个强分类器，从而提高模型的准确率和泛化能力。

>至此，利用Pyhon对酒店评论进行中文情感极性分析的大致过程已经介绍完毕。本项目中的部分代码参考自(https://github.com/AimeeLee77/senti_analysis)
具体代码实现来自(https://github.com/AimeeLee77/senti_analysis)、（https://blog.csdn.net/ifhuke/article/details/127829257）、(https://www.cnblogs.com/always-fight/p/10304806.html)
